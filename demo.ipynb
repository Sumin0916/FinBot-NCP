{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912cd8c6-d405-4dfe-8897-46108e6a6af7",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631b09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: An OpenAI API key must be set here for application initialization, even if not in use.\n",
    "# If you're not utilizing OpenAI models, assign a placeholder string (e.g., \"not_used\").\n",
    "import os, json\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d7d995-7beb-40b5-9a44-afd350b7d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/json_data/escaped_20221114000599.json', 'r') as file: #\"POSCO홀딩스\"\n",
    "    text = json.load(file)\n",
    "text = text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d51ebd-5597-4fdd-8c37-32636395081b",
   "metadata": {},
   "source": [
    "1) **Building**: RAPTOR recursively embeds, clusters, and summarizes chunks of text to construct a tree with varying levels of summarization from the bottom up. You can create a tree from the text in 'sample.txt' using `RA.add_documents(text)`.\n",
    "\n",
    "2) **Querying**: At inference time, the RAPTOR model retrieves information from this tree, integrating data across lengthy documents at different abstraction levels. You can perform queries on the tree with `RA.answer_question`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f58830-9004-48a4-b50e-61a855511d24",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3753fcf9-0a8e-4ab3-bf3a-6be38ef6cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:37:52,607 - Loading faiss.\n",
      "2024-11-12 13:37:52,628 - Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig\n",
    "from raptor.custom_tokenizer import FinQATokenizer\n",
    "from raptor.SummarizationModels import HCX_003_SummarizationModel, NCPSummarizationModel\n",
    "from raptor.ExtractModel import HCX_003_MetaDataExecutor\n",
    "from raptor.cluster_utils import FinRAG_Clustering\n",
    "from raptor.QAModels import HCX_003_QAModel\n",
    "from raptor.EmbeddingModels import (\n",
    "    BaseEmbeddingModel,\n",
    "    OpenAIEmbeddingModel,\n",
    "    HyperCLOVAEmbeddingModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4814086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RetrievalAugmentationConfig(\n",
    "    # 토크나이저 설정\n",
    "    tree_builder_type=\"cluster\",  # cluster 타입 사용\n",
    "    tb_clustering_algorithm=FinRAG_Clustering,  # FinRAG Clustering 알고리즘 사용\n",
    "\n",
    "    tb_tokenizer=FinQATokenizer(chunk_size=1024),  # 기본 chunk_size 설정\n",
    "    tr_tokenizer=FinQATokenizer(chunk_size=1024),  # retriever용 토크나이저\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    #embedding_model=HyperCLOVAEmbeddingModel(),  # 사용할 임베딩 모델 지정\n",
    "    \n",
    "    # 요약 모델 설정\n",
    "    summarization_model=HCX_003_SummarizationModel(),\n",
    "\n",
    "    # QA 모델 설정\n",
    "    qa_model=HCX_003_QAModel(),\n",
    "\n",
    "    # TreeBuilder 설정\n",
    "    tb_metadata_extract_model=\"HCX-003\",\n",
    "    tb_max_tokens=1000,  # 각 노드의 최대 토큰 수\n",
    "    tb_num_layers=5,     # 트리의 계층 수\n",
    "    tb_threshold=0.5,    # 유사도 임계값\n",
    "    tb_top_k=5,         # 상위 K개 노드 선택\n",
    "    tb_selection_mode=\"top_k\",  # 노드 선택 모드\n",
    "    tb_summarization_length=100,  # 요약 길이\n",
    "    \n",
    "    # TreeRetriever 설정\n",
    "    tr_threshold=0.5,    # 검색 임계값\n",
    "    tr_top_k=5,         # 검색할 상위 노드 수\n",
    "    tr_selection_mode=\"top_k\",  # 검색 모드\n",
    "    tr_num_layers=None,  # 검색할 계층 수 (None=전체)\n",
    "    tr_start_layer=None  # 검색 시작 계층 (None=최상위)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e843edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:37:52,677 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: FinQATokenizer\n",
      "            Max Tokens: 1000\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.HCX_003_SummarizationModel object at 0x320c51c00>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x320c51ed0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: FinRAG_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "Layer Summarization Lengths: {0: 300, 1: 200, 2: 100, 3: 1000}\n",
      "2024-11-12 13:37:52,677 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: FinQATokenizer\n",
      "            Max Tokens: 1000\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.HCX_003_SummarizationModel object at 0x320c51c00>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x320c51ed0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: FinRAG_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "Layer Summarization Lengths: {0: 300, 1: 200, 2: 100, 3: 1000}\n",
      "2024-11-12 13:37:52,678 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: FinQATokenizer\n",
      "            Max Tokens: 1000\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.HCX_003_SummarizationModel object at 0x320c51c00>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x320c51ed0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: FinRAG_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "Layer Summarization Lengths: {0: 300, 1: 200, 2: 100, 3: 1000}\n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: FinQATokenizer\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x320c53a90>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <raptor.QAModels.HCX_003_QAModel object at 0x320c51c30>\n",
      "            Tree Builder Type: cluster\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "RA = RetrievalAugmentation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3a453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:37:52,980 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,032 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,037 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,045 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,146 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,147 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,155 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,198 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,210 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,262 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,281 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,305 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,322 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,339 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,375 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,449 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,460 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,550 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,565 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,567 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,603 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,614 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,639 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,704 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,710 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,789 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,868 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,939 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,945 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,949 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,973 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,989 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:53,993 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,030 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,082 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,154 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,187 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,230 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,240 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,240 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,263 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,284 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,303 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,374 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,384 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,471 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,497 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,518 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,530 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,539 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,596 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,602 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,618 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,700 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,769 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,776 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,803 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,909 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,913 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:54,921 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,001 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,011 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,011 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,012 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,049 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,052 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,056 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,097 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,180 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,281 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,281 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,301 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,310 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,315 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,328 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,350 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,359 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,451 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,464 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,509 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,553 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,584 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,603 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,629 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,657 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,682 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,741 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,759 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,761 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,762 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,793 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,863 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,907 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,909 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,959 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:55,968 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,016 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,038 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,082 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,093 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,139 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,146 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,149 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,170 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,215 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,227 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,251 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,324 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,366 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,512 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,560 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:37:56,564 - Created 111 Leaf Embeddings\n",
      "2024-11-12 13:37:56,564 - Building All Nodes\n",
      "2024-11-12 13:37:56,607 - Using Cluster TreeBuilder\n",
      "2024-11-12 13:37:56,608 - Constructing Layer 0\n",
      "2024-11-12 13:37:56,608 - Summarization Length: 100\n",
      "2024-11-12 13:37:56,608 - Constructing Layer 1\n",
      "2024-11-12 13:37:56,609 - Stopping Layer construction: Cannot Create More Layers. Total Layers in tree: 1\n",
      "2024-11-12 13:37:56,609 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: FinQATokenizer\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x320c53a90>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# construct the tree\n",
    "RA.add_documents(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219d60a-1f0b-4cee-89eb-2ae026f13e63",
   "metadata": {},
   "source": [
    "### Querying from the tree\n",
    "\n",
    "```python\n",
    "question = # any question\n",
    "RA.answer_question(question)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4037c5-ad5a-424b-80e4-a67b8e00773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:49:10,777 - Using collapsed_tree\n",
      "2024-11-12 13:49:11,149 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-12 13:49:15,453 - Using collapsed_tree\n",
      "2024-11-12 13:49:15,964 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:  포스코는 국내 신용평가기관인 NICE신용평가, 한국신용평가, 한국기업평가로부터 AA+(Positive/Stable)의 신용등급을 받았고, 해외신용평가기관인 S&P로부터 BBB+(Positive), Moody's로부터 Baa1(Stable)의 신용등급을 받았습니다.\n",
      "\n",
      "Search result : - 회사채 신용등급의 정의(해외)\n",
      "\n",
      "※ 신용등급체계- 회사채 신용등급의 정의(국내)\n",
      "\n",
      "신용평가에 관한 사항 회사는 보고서 제출일 현재 국내 신용평가기관인 NICE신용평가로부터 AA+(Positive), 한국신용평가, 한국기업평가로부터 AA+(Stable)의 신용등급을 받고 있으며, 해외신용평가기관인 S BBB+(Positive), Moody&#x27;s로부터 Baa1(Stable)의 신용등급을 받고 있습니다. 회사가 최근 3사업연도 신용평가 전문기관으로부터 받은 신용평가등급은 다음과 같습니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"포스코 회사채 신용등급은 뭐고 누구에게 해당 신용 등급을 받았어?\"\n",
    "\n",
    "answer = RA.answer_question(question=question)\n",
    "search_res = RA.retrieve(question=\"회사채 신용등급\",top_k=3)\n",
    "print(\"\\nAnswer: \", answer)\n",
    "print(f\"\\nSearch result :\",search_res[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
